{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Part 1\n",
    "### <center> Beating benchmarks in \"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). The task is to beat \"Assignment 6 baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_auc_score = 0\n",
    "prev_cv_score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = ('../../data')\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'websites_train_sessions.csv'), index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'websites_test_sessions.csv'), index_col='session_id')\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "train_df.drop(train_df[train_df['time1']<'2013-09-01'].index, axis=0, inplace=True)\n",
    "\n",
    "# Load websites dictionary\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "    \n",
    "inv_site_dict = {v: k for k, v in site_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate target feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]\n",
    "\n",
    "# Column names for sites and times\n",
    "sitescolumns = ['site%s' % i for i in range(1, 11)]\n",
    "timescolumns = ['time%s' % i for i in range(1, 11)]\n",
    "\n",
    "full_df[timescolumns] = full_df[timescolumns].apply(pd.to_datetime)\n",
    "full_df[sitescolumns] = full_df[sitescolumns].fillna(-1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318980, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>41476</td>\n",
       "      <td>41475</td>\n",
       "      <td>6725</td>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>6725</td>\n",
       "      <td>41475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124706</th>\n",
       "      <td>41476</td>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>6725</td>\n",
       "      <td>41476</td>\n",
       "      <td>6725</td>\n",
       "      <td>41475</td>\n",
       "      <td>41476</td>\n",
       "      <td>41476</td>\n",
       "      <td>41476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239542</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>722</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173721</th>\n",
       "      <td>820</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>982</td>\n",
       "      <td>812</td>\n",
       "      <td>39</td>\n",
       "      <td>676</td>\n",
       "      <td>812</td>\n",
       "      <td>5932</td>\n",
       "      <td>679</td>\n",
       "      <td>812</td>\n",
       "      <td>679</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "4633        41475  41475  41476  41475   6725  41475  41475  41475   6725   \n",
       "124706      41476  41475  41475   6725  41476   6725  41475  41476  41476   \n",
       "239542         21     21     22     23     21     22     23     21    722   \n",
       "173721        820     21     21     23     22     23     22     21     -1   \n",
       "12984         982    812     39    676    812   5932    679    812    679   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "4633         41475  \n",
       "124706       41476  \n",
       "239542          -1  \n",
       "173721          -1  \n",
       "12984          676  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the same as in Assignment 4\n",
    "full_sites = full_df[sitescolumns]\n",
    "print(full_sites.shape)\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence of indices\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# and the matrix we are looking for\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Tf-Idf features based on sites. You can use `ngram_range`=(1, 3) and `max_features`=100000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites['sites'] = full_sites.astype(str).apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>sites</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>41476</td>\n",
       "      <td>41475</td>\n",
       "      <td>6725</td>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>6725</td>\n",
       "      <td>41475</td>\n",
       "      <td>41475 41475 41476 41475 6725 41475 41475 41475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124706</th>\n",
       "      <td>41476</td>\n",
       "      <td>41475</td>\n",
       "      <td>41475</td>\n",
       "      <td>6725</td>\n",
       "      <td>41476</td>\n",
       "      <td>6725</td>\n",
       "      <td>41475</td>\n",
       "      <td>41476</td>\n",
       "      <td>41476</td>\n",
       "      <td>41476</td>\n",
       "      <td>41476 41475 41475 6725 41476 6725 41475 41476 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239542</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>722</td>\n",
       "      <td>-1</td>\n",
       "      <td>21 21 22 23 21 22 23 21 722 -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173721</th>\n",
       "      <td>820</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>820 21 21 23 22 23 22 21 -1 -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>982</td>\n",
       "      <td>812</td>\n",
       "      <td>39</td>\n",
       "      <td>676</td>\n",
       "      <td>812</td>\n",
       "      <td>5932</td>\n",
       "      <td>679</td>\n",
       "      <td>812</td>\n",
       "      <td>679</td>\n",
       "      <td>676</td>\n",
       "      <td>982 812 39 676 812 5932 679 812 679 676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "4633        41475  41475  41476  41475   6725  41475  41475  41475   6725   \n",
       "124706      41476  41475  41475   6725  41476   6725  41475  41476  41476   \n",
       "239542         21     21     22     23     21     22     23     21    722   \n",
       "173721        820     21     21     23     22     23     22     21     -1   \n",
       "12984         982    812     39    676    812   5932    679    812    679   \n",
       "\n",
       "            site10                                              sites  \n",
       "session_id                                                             \n",
       "4633         41475  41475 41475 41476 41475 6725 41475 41475 41475...  \n",
       "124706       41476  41476 41475 41475 6725 41476 6725 41475 41476 ...  \n",
       "239542          -1                     21 21 22 23 21 22 23 21 722 -1  \n",
       "173721          -1                     820 21 21 23 22 23 22 21 -1 -1  \n",
       "12984          676            982 812 39 676 812 5932 679 812 679 676  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236183, 100000)\n",
      "(82797, 100000)\n",
      "(318980, 100000)\n"
     ]
    }
   ],
   "source": [
    "# You code here\n",
    "#tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features = 100000) #change to None\n",
    "#tfidf_matrix = tfidf.fit_transform(full_sites['sites'])\n",
    "#vect_df = vect.fit_transform(full_sites['site1'].astype(str))\n",
    "#tfidf_matrix = tfidftrans.fit_transform(vect_df)\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1, 3), max_features=100000)\n",
    "tfidf_train = vect.fit_transform(full_sites[:idx_split]['sites'])\n",
    "tfidf_test = vect.transform(full_sites[idx_split:]['sites'])\n",
    "print(tfidf_train.shape)\n",
    "print(tfidf_test.shape)\n",
    "tfidf_matrix = vstack([tfidf_train, tfidf_test])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features based on the session start time: hour, whether it's morning, day or night and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_month</th>\n",
       "      <th>hour</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>201309</td>\n",
       "      <td>7</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124706</th>\n",
       "      <td>201309</td>\n",
       "      <td>8</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239542</th>\n",
       "      <td>201309</td>\n",
       "      <td>8</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173721</th>\n",
       "      <td>201309</td>\n",
       "      <td>8</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>201309</td>\n",
       "      <td>8</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_month  hour  seconds\n",
       "session_id                            \n",
       "4633             201309     7    285.0\n",
       "124706           201309     8    729.0\n",
       "239542           201309     8     94.0\n",
       "173721           201309     8    104.0\n",
       "12984            201309     8     38.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create separate dataframes for numerical and for binary (OHE) features\n",
    "numerical_df = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "numerical_df['start_month'] = full_df['time1'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "numerical_df['hour'] = full_df['time1'].apply(lambda ts: ts.hour)\n",
    "\n",
    "# minute slightly reduces CV score\n",
    "#numerical_df['minute'] = full_df['time1'].apply(lambda ts: ts.hour*60+ts.minute)\n",
    "# Find sessions' starting and ending\n",
    "numerical_df['min'] = full_df[timescolumns].min(axis=1)\n",
    "numerical_df['max'] = full_df[timescolumns].max(axis=1)\n",
    "\n",
    "# Calculate sessions' duration in seconds\n",
    "numerical_df['seconds'] = (numerical_df['max'] - numerical_df['min']) / np.timedelta64(1, 's')\n",
    "\n",
    "# Calculate differences between times\n",
    "#from __future__ import division\n",
    "#numerical_df['diffs'] =full_df[timescolumns].apply(lambda row: [pd.Timedelta(sorted(row)[n] - sorted(row)[n-1]).seconds for n in range(1,10)], axis=1)\n",
    "#numerical_df['max_interval'] = numerical_df['diffs'].apply(lambda lst: max(lst)).fillna(0)\n",
    "#numerical_df['min_interval'] = numerical_df['diffs'].apply(lambda lst: min(lst)).fillna(0)\n",
    "#numerical_df['mean_interval'] = numerical_df['diffs'].apply(lambda lst: np.mean(lst)).fillna(0)\n",
    "#numerical_df.drop(['diffs'], axis=1, inplace=True)\n",
    "\n",
    "numerical_df.drop(['max', 'min'], axis=1, inplace=True)\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>morning</th>\n",
       "      <th>day</th>\n",
       "      <th>evening</th>\n",
       "      <th>night</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>dayofweek_0</th>\n",
       "      <th>dayofweek_1</th>\n",
       "      <th>dayofweek_2</th>\n",
       "      <th>dayofweek_3</th>\n",
       "      <th>dayofweek_4</th>\n",
       "      <th>dayofweek_5</th>\n",
       "      <th>dayofweek_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124706</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239542</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173721</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            morning  day  evening  night  is_weekend  dayofweek_0  \\\n",
       "session_id                                                          \n",
       "4633              1    0        0      0           0            0   \n",
       "124706            1    0        0      0           0            0   \n",
       "239542            1    0        0      0           0            0   \n",
       "173721            1    0        0      0           0            0   \n",
       "12984             1    0        0      0           0            0   \n",
       "\n",
       "            dayofweek_1  dayofweek_2  dayofweek_3  dayofweek_4  dayofweek_5  \\\n",
       "session_id                                                                    \n",
       "4633                  0            0            1            0            0   \n",
       "124706                0            0            1            0            0   \n",
       "239542                0            0            1            0            0   \n",
       "173721                0            0            1            0            0   \n",
       "12984                 0            0            1            0            0   \n",
       "\n",
       "            dayofweek_6  \n",
       "session_id               \n",
       "4633                  0  \n",
       "124706                0  \n",
       "239542                0  \n",
       "173721                0  \n",
       "12984                 0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_df = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "categ_df['morning'] = ((numerical_df['hour'] >= 7) & (numerical_df['hour'] < 11)).astype(np.int32)\n",
    "categ_df['day'] = ((numerical_df['hour'] >= 11) & (numerical_df['hour'] < 17)).astype(np.int32)\n",
    "categ_df['evening'] = ((numerical_df['hour'] >= 17) & (numerical_df['hour'] <= 21)).astype(np.int32)\n",
    "categ_df['night'] = ((numerical_df['hour'] >= 22) | (numerical_df['hour'] < 7)).astype(np.int32)\n",
    "categ_df['is_weekend'] = full_df['time1'].apply(lambda x: 1 if x.date().weekday() in (5, 6) else 0)\n",
    "\n",
    "ohe_weekday_df = pd.get_dummies(full_df['time1'].apply(lambda ts: ts.dayofweek), prefix='dayofweek')\n",
    "ohe_hour_df = pd.get_dummies(full_df['time1'].apply(lambda ts: ts.hour), prefix='hour')\n",
    "ohe_daymonth_df = pd.get_dummies(full_df['time1'].apply(lambda ts: ts.day), prefix='day')\n",
    "ohe_month_df = pd.get_dummies(full_df['time1'].apply(lambda ts: ts.month), prefix='month')\n",
    "\n",
    "categ_df = pd.concat([categ_df, \n",
    "                      ohe_weekday_df,\n",
    "#                      ohe_hour_df, \n",
    "#                     ohe_daymonth_df\n",
    "#                      ohe_month_df\n",
    "], axis=1)\n",
    "\n",
    "#for col in ['morning', 'day', 'evening', 'night']:\n",
    "#    categ_df[col + '_weekend'] = categ_df[col] * categ_df['is_weekend']\n",
    "    \n",
    "#for i in range(7, 24):\n",
    "#    categ_df['weekend_hour_' + str(i)] = categ_df['hour_' + str(i)] * categ_df['is_weekend']\n",
    "#numerical_df.drop(['hour'], axis=1, inplace=True)\n",
    "categ_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#poly = PolynomialFeatures(2)\n",
    "#categ_df = poly.fit_transform(categ_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale these features and combine them with Tf-Idf based on sites (you'll need `scipy.sparse.hstack`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add quadratic features for numericals\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#poly = PolynomialFeatures(2)\n",
    "#numerical_df = poly.fit_transform(numerical_df)\n",
    "#print(numerical_df.shape)\n",
    "#print(poly_df.shape)\n",
    "\n",
    "#scaler = StandardScaler().fit(poly_df[:idx_split])\n",
    "#numerical_scaled_df = scaler.transform(poly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(numerical_df[:idx_split])\n",
    "numerical_df = scaler.transform(numerical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#catscaler = StandardScaler().fit(categ_df[:idx_split])\n",
    "#categ_df = catscaler.transform(categ_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_matrix = hstack([tfidf_matrix, numerical_df, categ_df, full_sites_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318980, 148386)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  10 | elapsed:  2.5min remaining:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  2.9min remaining:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:  3.3min remaining:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:  3.8min remaining:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  4.1min remaining:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  4.3min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  10 | elapsed:  4.7min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  6.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 2.09 s, total: 13 s\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = full_matrix[:idx_split,:]\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "lrcv = LogisticRegressionCV(scoring='roc_auc',\n",
    "                            #penalty='l1', solver='saga',\n",
    "                            Cs=np.logspace(-3,1,40), \n",
    "                            #class_weight='balanced',\n",
    "                            #Cs=10,\n",
    "                            random_state=42,\n",
    "                            cv=tss, n_jobs=-1, verbose = 20)\n",
    "lrcv.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-03 1.26638017e-03 1.60371874e-03 2.03091762e-03\n",
      " 2.57191381e-03 3.25702066e-03 4.12462638e-03 5.22334507e-03\n",
      " 6.61474064e-03 8.37677640e-03 1.06081836e-02 1.34339933e-02\n",
      " 1.70125428e-02 2.15443469e-02 2.72833338e-02 3.45510729e-02\n",
      " 4.37547938e-02 5.54102033e-02 7.01703829e-02 8.88623816e-02\n",
      " 1.12533558e-01 1.42510267e-01 1.80472177e-01 2.28546386e-01\n",
      " 2.89426612e-01 3.66524124e-01 4.64158883e-01 5.87801607e-01\n",
      " 7.44380301e-01 9.42668455e-01 1.19377664e+00 1.51177507e+00\n",
      " 1.91448198e+00 2.42446202e+00 3.07029063e+00 3.88815518e+00\n",
      " 4.92388263e+00 6.23550734e+00 7.89652287e+00 1.00000000e+01]\n",
      "Best C: 1.1937766417144358\n",
      "Max auc_roc: 0.8967813746212071\n",
      "Prev max auc_roc: 0.8922137588873701\n"
     ]
    }
   ],
   "source": [
    "print(lrcv.Cs_)\n",
    "print('Best C:', lrcv.C_[0])\n",
    "print ('Max auc_roc:', lrcv.scores_[1].mean(axis=0).max()) \n",
    "print ('Prev max auc_roc:', prev_auc_roc_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_auc_roc_cv = lrcv.scores_[1].mean(axis=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, seed=42, ratio = 0.9):\n",
    "    # Split the data into the training and validation sets\n",
    "    idx = int(round(X.shape[0] * ratio))\n",
    "    # Classifier training\n",
    "    lr = LogisticRegression(C=C, \n",
    "                            #class_weight='balanced', \n",
    "                            random_state=seed, n_jobs=-1).fit(X[:idx, :], y[:idx])\n",
    "    # Prediction for validation set\n",
    "    y_pred = lr.predict_proba(X[idx:, :])[:, 1]\n",
    "    # Calculate the quality\n",
    "    score = roc_auc_score(y[idx:], y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9454616877262417\n",
      "0.9627963283267579\n",
      "CPU times: user 57.8 s, sys: 1min 22s, total: 2min 20s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auc_score = get_auc_lr_valid(X_train, y, C=lrcv.C_[0], ratio = 0.75)\n",
    "print(auc_score)\n",
    "print(prev_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_auc_score = auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.7130449650705917, total=   3.1s\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.6634365943973383, total=  12.4s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.9704183017095144, total=  36.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   37.1s remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.8805752534959241, total=  45.5s\n",
      "[CV] ........................ , score=0.956382470650017, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:  1.1min remaining:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.965268144441338, total= 1.1min\n",
      "[CV] ....................... , score=0.9465809072444142, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  1.3min remaining:   33.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.943970805186738, total= 1.3min\n",
      "[CV] ....................... , score=0.8892298351314745, total= 1.6min\n",
      "[CV] ....................... , score=0.9700570566322441, total= 1.6min\n",
      "0.8898964333959594\n",
      "0.8790266910387536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(LogisticRegression(C=lrcv.C_[0], random_state=42, n_jobs=-1), \n",
    "                            X_train, y, \n",
    "                            scoring='roc_auc', cv=tss, \n",
    "                            n_jobs=-1, verbose=10)\n",
    "print(np.mean(cv_scores))\n",
    "print(prev_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_cv_score = np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for the test set and form a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = full_matrix[idx_split:,:]\n",
    "test_pred = lrcv.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"565c5c60-c445-46c4-aab0-da04aa40899d\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"565c5c60-c445-46c4-aab0-da04aa40899d\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "write_to_submission_file(test_pred, \"assignment6_alice_submission_tss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try some LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary', \n",
    "          'nthread': 5, # Updated from nthread\n",
    "          'num_leaves': 64, \n",
    "          'learning_rate': 0.05, \n",
    "          'max_bin': 512, \n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1, \n",
    "          'subsample_freq': 1, \n",
    "          'colsample_bytree': 0.8, \n",
    "          'reg_alpha': 5, \n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5, \n",
    "          'min_child_weight': 1, \n",
    "          'min_child_samples': 5, \n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [16,24,128],\n",
    "    'num_leaves': [6,8,16,32],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.64],\n",
    "    'subsample' : [0.7],\n",
    "    'reg_alpha' : [1],\n",
    "    'reg_lambda' : [1,1.4],\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
    "          objective = 'binary', \n",
    "          n_jobs = 5, # Updated from 'nthread' \n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'], \n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'], \n",
    "          subsample_freq = params['subsample_freq'], \n",
    "          min_split_gain = params['min_split_gain'], \n",
    "          min_child_weight = params['min_child_weight'], \n",
    "          min_child_samples = params['min_child_samples'], \n",
    "          scale_pos_weight = params['scale_pos_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.7min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-951024b4888d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTimeSeriesSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run the grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the best parameters found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "\n",
    "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=TimeSeriesSplit(n_splits=4), n_jobs=-1)\n",
    "# Run the grid\n",
    "grid.fit(X_train, y)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
