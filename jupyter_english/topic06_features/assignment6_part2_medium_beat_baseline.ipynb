{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6\n",
    "### <center> Beating benchmarks in \"How good is your Medium article?\"\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"Assignment 6 baseline\". Do not forget about our shared [\"primitive\" baseline](https://github.com/Yorko/mlcourse_open/blob/master/jupyter_english/topic04_linear_models/kaggle_medium_ridge_baseline.ipynb) - you'll find something valuable there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle \n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data,\n",
    "                               inp_filename, is_train=True):\n",
    "    \n",
    "    features = ['content', 'published', 'title', 'author', 'description', 'readtime', 'domain']\n",
    "    prefix = 'train' if is_train else 'test'\n",
    "    feature_files = [open(os.path.join(path_to_data,\n",
    "                                       '{}_{}.txt'.format(prefix, feat)),\n",
    "                          'w', encoding='utf-8')\n",
    "                     for feat in features]\n",
    "    \n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as inp_json_file:\n",
    "\n",
    "        for line in tqdm_notebook(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            \n",
    "            # You code here\n",
    "            content = json_data['content'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            content_no_html_tags = strip_tags(content)\n",
    "            feature_files[0].write(content_no_html_tags + '\\n')\n",
    "            \n",
    "            published = json_data['published']['$date']\n",
    "            feature_files[1].write(published + '\\n')\n",
    "            \n",
    "            title = json_data['title'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            feature_files[2].write(title + '\\n')\n",
    "            \n",
    "            author = json_data['author']\n",
    "            author2 = json_data['meta_tags']['author'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            feature_files[3].write('{},{},{},{}\\n'.format(author['name'],\n",
    "                                                          author['url'],\n",
    "                                                          author['twitter'],\n",
    "                                                          author2))\n",
    "            \n",
    "            description = json_data['meta_tags']['description'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            feature_files[4].write(description + '\\n')\n",
    "            \n",
    "            read_time_txt = json_data['meta_tags']['twitter:data1']\n",
    "            read_time = read_time_txt.split()[0] if read_time_txt.split()[0].isdigit() else '0'\n",
    "            feature_files[5].write(read_time + '\\n')\n",
    "            \n",
    "            domain = json_data['domain'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            feature_files[6].write(domain + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../raw_data' # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
    "    - Bag of authors (i.e. One-Hot-Encoded author names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here\n",
    "def contentFeature():\n",
    "    tfidf = TfidfVectorizer(ngram_range = (1,3), max_features=150000)\n",
    "    with open(os.path.join(PATH_TO_DATA, 'train_content.txt'), encoding='utf-8') as input_file:\n",
    "        X_train = tfidf.fit_transform(input_file)\n",
    "    with open(os.path.join(PATH_TO_DATA, 'test_content.txt'), encoding='utf-8') as input_file:\n",
    "        X_test = tfidf.transform(input_file)\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def titleFeature():\n",
    "    tfidf = TfidfVectorizer(ngram_range = (1,3), max_features=None)\n",
    "    with open(os.path.join(PATH_TO_DATA, 'train_title.txt'), encoding='utf-8') as input_file:\n",
    "        X_train = tfidf.fit_transform(input_file)\n",
    "    with open(os.path.join(PATH_TO_DATA, 'test_title.txt'), encoding='utf-8') as input_file:\n",
    "        X_test = tfidf.transform(input_file)\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dateFeature():\n",
    "    train_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_published.txt'), header = None, names=['timestamp'])\n",
    "    test_df = pd.read_csv(os.path.join(PATH_TO_DATA,'test_published.txt'), header = None, names=['timestamp'])\n",
    "    \n",
    "    train_idx = train_df.shape[0]\n",
    "    print(train_df.shape)\n",
    "    \n",
    "    times_df = pd.concat([train_df, test_df], ignore_index=True)        \n",
    "    \n",
    "    times_df['timestamp'] = pd.to_datetime(times_df['timestamp'])\n",
    "    times_df['start_month'] = times_df['timestamp'].apply(lambda ts: 100 * ts.year + ts.month)\n",
    "    times_df['hour'] = times_df['timestamp'].apply(lambda ts: ts.hour).astype(int)\n",
    "    times_df['morning'] = ((times_df['hour'] >= 7) & (times_df['hour'] < 10)).astype(np.int32)\n",
    "    times_df['day'] = ((times_df['hour'] >= 10) & (times_df['hour'] < 19)).astype(np.int32)\n",
    "    times_df['evening'] = ((times_df['hour'] >= 19) & (times_df['hour'] < 22)).astype(np.int32)\n",
    "    times_df['night'] = ((times_df['hour'] >= 22) | (times_df['hour'] < 7)).astype(np.int32)\n",
    "    times_df['is_weekend'] = times_df['timestamp'].apply(lambda x: 1 if x.date().weekday() in (5, 6) else 0)\n",
    "    ohe_weekday_df = pd.get_dummies(times_df['timestamp'].apply(lambda ts: ts.dayofweek), prefix='dayofweek')\n",
    "    ohe_hour_df = pd.get_dummies(times_df['timestamp'].apply(lambda ts: ts.hour), prefix='hour')\n",
    "    ohe_daymonth_df = pd.get_dummies(times_df['timestamp'].apply(lambda ts: ts.day), prefix='day')\n",
    "    times_df = pd.concat([times_df, ohe_weekday_df, ohe_hour_df, ohe_daymonth_df], axis=1)\n",
    "    times_df.drop(['timestamp'], axis=1, inplace=True)\n",
    "    \n",
    "    res_df = StandardScaler().fit_transform(times_df)\n",
    "    return (res_df[:train_idx], res_df[train_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def authorFeature():\n",
    "    train_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_author.txt'), header = None, names=['name', 'site', 'twitter', 'author'])\n",
    "    test_df = pd.read_csv(os.path.join(PATH_TO_DATA,'test_author.txt'), header = None, names=['name', 'site', 'twitter', 'author'])\n",
    "    \n",
    "    train_idx = train_df.shape[0]\n",
    "    \n",
    "    author_df = pd.concat([train_df, test_df], ignore_index=True)        \n",
    "    enc = OneHotEncoder()\n",
    "    labeler = LabelEncoder()\n",
    "    \n",
    "    #res_df = pd.get_dummies(author_df['author'], prefix='author')\n",
    "    res_df = enc.fit_transform(labeler.fit_transform(author_df['author'].ravel()).reshape((author_df.shape[0], 1)))\n",
    "    \n",
    "    return (res_df[:train_idx], res_df[train_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descriptionFeature():\n",
    "    tfidf = TfidfVectorizer(ngram_range = (1,3), max_features=None)\n",
    "    with open(os.path.join(PATH_TO_DATA, 'train_description.txt'), encoding='utf-8') as input_file:\n",
    "        X_train = tfidf.fit_transform(input_file)\n",
    "    with open(os.path.join(PATH_TO_DATA, 'test_description.txt'), encoding='utf-8') as input_file:\n",
    "        X_test = tfidf.transform(input_file)\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def domainFeature():\n",
    "    train_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_domain.txt'), header = None, names=['domain'])\n",
    "    test_df = pd.read_csv(os.path.join(PATH_TO_DATA,'test_domain.txt'), header = None, names=['domain'])\n",
    "    train_idx = train_df.shape[0]\n",
    "    print(train_df.shape, test_df.shape)\n",
    "    \n",
    "    domain_df = pd.concat([train_df, test_df], ignore_index=True)        \n",
    "    enc = OneHotEncoder()\n",
    "    labeler = LabelEncoder()\n",
    "    \n",
    "    #res_df = pd.get_dummies(author_df['author'], prefix='author')\n",
    "    label_df = labeler.fit_transform(domain_df['domain'].fillna('empty').ravel()).reshape((domain_df.shape[0], 1))\n",
    "    res_df = enc.fit_transform(label_df)\n",
    "    return (res_df[:train_idx], res_df[train_idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTimeFeature():\n",
    "    train_df = pd.read_csv(os.path.join(PATH_TO_DATA,'train_readtime.txt'), header = None, names=['readtime'])\n",
    "    test_df = pd.read_csv(os.path.join(PATH_TO_DATA,'test_readtime.txt'), header = None, names=['readtime'])\n",
    "    return (StandardScaler().fit_transform(train_df), StandardScaler().fit_transform(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 424 ms, sys: 24.9 ms, total: 449 ms\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_author_sparse, X_test_author_sparse = authorFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62313, 1)\n",
      "CPU times: user 3.01 s, sys: 291 ms, total: 3.3 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_time_features_sparse, X_test_time_features_sparse = dateFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 54s, sys: 40.3 s, total: 30min 34s\n",
      "Wall time: 32min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_content_sparse, X_test_content_sparse = contentFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"X_train_content_sparse\", 'wb') as f:\n",
    "    pickle.dump(X_train_content_sparse, f)\n",
    "with open(\"X_test_content_sparse\", 'wb') as f:\n",
    "    pickle.dump(X_test_content_sparse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"X_train_content_sparse\", 'rb') as f:\n",
    "    X_train_content_sparse = pickle.load(f)\n",
    "with open(\"X_test_content_sparse\", 'rb') as f:\n",
    "    X_test_content_sparse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62313, 2454321) (34645, 2454321)\n",
      "CPU times: user 29.5 s, sys: 880 ms, total: 30.4 s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_description_sparse, X_test_description_sparse = descriptionFeature()\n",
    "print(X_train_description_sparse.shape, X_test_description_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62313, 728646) (34645, 728646)\n",
      "CPU times: user 7.32 s, sys: 172 ms, total: 7.49 s\n",
      "Wall time: 7.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_title_sparse, X_test_title_sparse = titleFeature()\n",
    "print(X_train_title_sparse.shape, X_test_title_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62313, 1) (34645, 1)\n",
      "(62313, 247) (34645, 247)\n",
      "CPU times: user 79.2 ms, sys: 161 Âµs, total: 79.4 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_domain, X_test_domain = domainFeature()\n",
    "print(X_train_domain.shape, X_test_domain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62313, 1) (34645, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_readtime, X_test_readtime = readTimeFeature()\n",
    "print(X_train_readtime.shape, X_test_readtime.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse = csr_matrix(hstack([X_train_content_sparse, X_train_title_sparse,\n",
    "                                    X_train_author_sparse, X_train_time_features_sparse, \n",
    "                                    X_train_title_sparse, X_train_domain, X_train_readtime,\n",
    "                                    X_train_description_sparse]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_sparse = csr_matrix(hstack([X_test_content_sparse, X_test_title_sparse,\n",
    "                                   X_test_author_sparse, X_test_time_features_sparse,\n",
    "                                   X_test_title_sparse, X_test_domain, X_test_readtime,\n",
    "                                   X_test_description_sparse]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"X_train_sparse\", 'wb') as f:\n",
    "    pickle.dump(X_train_sparse, f)\n",
    "with open(\"X_test_sparse\", 'wb') as f:\n",
    "    pickle.dump(X_test_sparse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"X_train_sparse\", 'rb') as f:\n",
    "    X_train_sparse = pickle.load(f)\n",
    "with open(\"X_test_sparse\", 'rb') as f:\n",
    "    X_test_sparse = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of target values:  3.051538598205832\n"
     ]
    }
   ],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA,'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values\n",
    "print('Mean of target values: ', np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "\n",
    "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43619, 4105814) (18694, 4105814)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_part_sparse.shape, X_valid_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You code here\n",
    "from sklearn.linear_model import Ridge,RidgeCV,SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ridge = RidgeCV(alphas=np.logspace(-5,-1,5), scoring='neg_mean_absolute_error', cv=5)\n",
    "ridge.fit(X_train_part_sparse, y_train_part);\n",
    "print(ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd = SGDRegressor(max_iter=1000)\n",
    "parameters = {'alpha': np.logspace(-15, -10, 5)}\n",
    "\n",
    "cv = GridSearchCV(estimator=sgd, cv=5, scoring='neg_mean_absolute_error', param_grid = parameters, n_jobs = -1, verbose = 10)\n",
    "cv.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cv.cv_results_)\n",
    "print('Best params:', cv.best_params_)\n",
    "print ('Min MAE:', -cv.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9a1ffd9c8dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mridge_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ridge' is not defined"
     ]
    }
   ],
   "source": [
    "ridge_pred = ridge.predict(X_valid_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_pred = cv.predict(X_valid_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_mae = mean_absolute_error(y_valid, ridge_pred)\n",
    "#valid_mae = mean_absolute_error(y_valid, sgd_pred)\n",
    "valid_mae, np.expm1(valid_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0779699901030595, 1.9387078857541236)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_mae = mean_absolute_error(y_valid, sgd_pred)\n",
    "sgd_mae, np.expm1(sgd_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ridge = RidgeCV(alphas=np.logspace(3,7,5), \n",
    "                scoring='neg_mean_absolute_error', cv=5)\n",
    "ridge.fit(X_train_sparse, y_train);\n",
    "print(ridge.alpha_)\n",
    "#sgd.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_test_pred = ridge.predict(scaler.fit_transform(X_test_sparse))\n",
    "#sgd_test_pred = sgd.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgdfinal = SGDRegressor(max_iter=1000, alpha=cv.best_params_['alpha'], penalty='l1')\n",
    "sgdfinal.fit(X_train_sparse, y_train)\n",
    "sgd_test_pred = sgdfinal.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] alpha=1e-06 .....................................................\n",
      "[CV] alpha=7.742636826811277e-06 .....................................\n",
      "[CV] alpha=7.742636826811277e-06 .....................................\n",
      "[CV] alpha=7.742636826811277e-06 .....................................\n"
     ]
    }
   ],
   "source": [
    "cv.fit(X_train_sparse, y_train)\n",
    "sgd_test_pred = cv.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:', cv.best_params_)\n",
    "print ('Min MAE:', -cv.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA,'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3de2b0212e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_submission_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'assignment6_medium_submission_ridge.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ridge_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "write_submission_file(ridge_test_pred, 'assignment6_medium_submission_ridge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sgd_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-72028cc09d50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_submission_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'assignment6_medium_submission_sgd.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sgd_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "write_submission_file(sgd_test_pred, 'assignment6_medium_submission_sgd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(ridge_test_pred), \n",
    "                      'medium_all_zeros_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mae_zero = 4.33328\n",
    "\n",
    "mean_submission = ridge_test_pred.mean()\n",
    "ridge_test_pred_modif = ridge_test_pred + mae_zero - mean_submission # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mae_zero = 4.33328\n",
    "\n",
    "mean_submission = sgd_test_pred.mean()\n",
    "test_pred_modif = sgd_test_pred + mae_zero - mean_submission # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_submission_file(test_pred_modif, \n",
    "                      'assignment6_medium_submission_with_hack.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
