{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: [Yury Kashnitsky](https://www.linkedin.com/in/festline), Data Scientist at Mail.Ru Group <br>\n",
    "Translated and edited by [Egor Polusmak](https://www.linkedin.com/in/egor-polusmak/), [Anastasia Manokhina](https://www.linkedin.com/in/anastasiamanokhina/), <br>[Evgene Mashkin](https://www.linkedin.com/in/eugene-mashkin-88490883/), and [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/).\n",
    "    \n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment #7. PCA and Clustering</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are going to walk through the built-in implementations for dimensionality reduction and clustering methods in `scikit-learn`. Answers should be submitted through [this web-form](https://goo.gl/forms/oPqLDP8nn9gSelSN2).\n",
    "\n",
    "## 1. Principal Component Analysis\n",
    "\n",
    "First, import all required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set(style='white')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the given toy data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[2., 13.], [1., 3.], [6., 19.],\n",
    "              [7., 18.], [5., 17.], [4., 9.],\n",
    "              [5., 22.], [6., 11.], [8., 25.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEHCAYAAABGNUbLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0affc85c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:, 1])\n",
    "plt.xlabel(r'$x_1$')\n",
    "plt.ylabel(r'$x_2$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1. What is the angle between the $x_1$ axis and the vector corresponding to the first principal component for this data (don't forget to rescale the data using StandardScaler)? \n",
    "- 30 degrees\n",
    "- 45 degrees\n",
    "- 60 degrees\n",
    "- 75 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.70710678 -0.70710678]\n",
      "45.0\n"
     ]
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=2).fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "vec1 = pca.components_[0]\n",
    "print(vec1)\n",
    "angle = np.arctan(vec1[1]/vec1[0])/np.pi*180\n",
    "print(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. </font> What are the eigenvalues of the $X^TX$ matrix, given $X$ is a rescaled matrix of the toy dataset?\n",
    "\n",
    " - 4 and 1.42\n",
    " - 16.2 and 2702.8\n",
    " - 4.02 and 51.99\n",
    " - 15.97 and 2.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.  ,  1.42])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "np.round(pca.singular_values_, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3. </font> What is the meaning of the two numbers from the previous question?\n",
    "\n",
    "\n",
    "- ##### their squares tell what part of the initial data's variance is explained by principal components\n",
    "- they define a rotation angle between the first principal component and the initial axis\n",
    "- those numbers tell what part of the initial data's variance is explained by principal components\n",
    "- the square roots of those numbers define a rotation angle between the first principal component and the initial axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a dataset of peoples' faces and output their names. (This step requires stable, fast internet connection.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to read the image file ../../data/faces\\lfw_home\\lfw_funneled\\Ariel_Sharon\\Ariel_Sharon_0001.jpg, Please make sure that libjpeg is installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f541667b49f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m lfw_people = datasets.fetch_lfw_people(min_faces_per_person=50, \n\u001b[1;32m----> 2\u001b[1;33m                 resize=0.4, data_home='../../data/faces')\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m print('%d objects, %d features, %d classes' % (lfw_people.data.shape[0],\n\u001b[0;32m      5\u001b[0m       lfw_people.data.shape[1], len(lfw_people.target_names)))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36mfetch_lfw_people\u001b[1;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing)\u001b[0m\n\u001b[0;32m    333\u001b[0m     faces, target, target_names = load_func(\n\u001b[0;32m    334\u001b[0m         \u001b[0mdata_folder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         min_faces_per_person=min_faces_per_person, color=color, slice_=slice_)\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;31m# pack the results as a Bunch instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    508\u001b[0m                           \u001b[1;34m'directory %s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[1;32m--> 510\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m                 \u001b[1;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36m_fetch_lfw_people\u001b[1;34m(data_folder_path, slice_, color, resize, min_faces_per_person)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperson_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;31m# shuffle the faces with a deterministic RNG scheme to avoid having\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36m_load_imgs\u001b[1;34m(file_paths, slice_, color, resize)\u001b[0m\n\u001b[0;32m    186\u001b[0m             raise RuntimeError(\"Failed to read the image file %s, \"\n\u001b[0;32m    187\u001b[0m                                \u001b[1;34m\"Please make sure that libjpeg is installed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                                % file_path)\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslice_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to read the image file ../../data/faces\\lfw_home\\lfw_funneled\\Ariel_Sharon\\Ariel_Sharon_0001.jpg, Please make sure that libjpeg is installed"
     ]
    }
   ],
   "source": [
    "lfw_people = datasets.fetch_lfw_people(min_faces_per_person=50, \n",
    "                resize=0.4, data_home='../../data/faces')\n",
    "\n",
    "print('%d objects, %d features, %d classes' % (lfw_people.data.shape[0],\n",
    "      lfw_people.data.shape[1], len(lfw_people.target_names)))\n",
    "print('\\nPersons:')\n",
    "for name in lfw_people.target_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some faces. All images are stored in a handy `lfw_people.images` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(15):\n",
    "    ax = fig.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(lfw_people.images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4. </font>What  **minimal** principal component number is needed to explain 90% of data variance (scaled using  StandardScaler)?\n",
    "\n",
    "- 75\n",
    "- 76\n",
    "- ##### 77\n",
    "- 78\n",
    "\n",
    "For this task, you should be using the [`svd_solver='randomized'`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) parameter, which is a PCA approximation, but it significantly increases performance on large data sets. Use fixed `random_state=1` for comparable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "scaler = StandardScaler().fit(lfw_people.data)\n",
    "scaled_data = scaler.transform(lfw_people.data)\n",
    "pca = PCA(n_components=80, svd_solver='randomized', random_state=1).fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), color='k', lw=2)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "plt.xlim(74, 80)\n",
    "plt.ylim(0.85, 0.95)\n",
    "plt.yticks(np.arange(0.85, 0.95, 0.01))\n",
    "plt.axvline(21, c='b')\n",
    "plt.axhline(0.9, c='r')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)[76]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a picture showing the first 30 principal components (don't be scared when you see the results). In order to create it, use 30 vectors from `pca.components_`, reshape them to their initial size (50 x 37), and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "#data = [pca.components_[i].reshape((50,37)) for i in range(0, 31)]\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "for i in range(30):\n",
    "    ax = fig.add_subplot(6, 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(pca.components_[i].reshape((50,37)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5. </font> Within the first 30 principal components, which one brightens the left side of the face? More specifically, which principal component corresponds to a linear combination of the initial features (pixels' intensity), which, when shown as an image, looks like a photo highlighted from the left side?\n",
    "\n",
    "- 1\n",
    "- ##### 2\n",
    "- 4\n",
    "- 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a projection of faces onto the space of the first two principal components. \n",
    "\n",
    "#### Question 6. </font> Who looks the least similar to the other people in the dataset if we only consider the two first principal components? \n",
    "\n",
    "To answer this question, take the first two principal components from the rescaled data, evaluate two mean principal components' values for each person over all their images in the dataset (again, use both svd_solver='randomized' and random_state=1). Then, with 12 two-dimensional points, find the one which has the largest distance from the others (by Euclidean distance). You can do this either precsisely or approximately using `sklearn.metrics.euclidean_distances` and `seaborn.heatmap`.\n",
    "\n",
    "- Colin Powell\n",
    "- George W Bush\n",
    "- Jacques Chirac\n",
    "- ##### Serena Williams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from seaborn import heatmap\n",
    "print(lfw_people.target_names)\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='randomized', random_state=1).fit(scaled_data)\n",
    "\n",
    "vectors = []\n",
    "for target, person in enumerate(lfw_people.target_names):\n",
    "    person_images = scaled_data[pd.Series(lfw_people.target) == target]\n",
    "    vectors.append(pca.transform(person_images).mean(axis=0))\n",
    "\n",
    "heatmap(euclidean_distances(vectors[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(lfw_people.target_names[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next question, load the housing prices dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the elbow-method (reference [article 7](https://habrahabr.ru/company/ods/blog/325654/) of the course), find the optimal number of clusters to set as a hyperparameter for the k-means algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7. </font> What is the optimal number of clusters to use on housing prices data set according to the elbow-method? Use `random_state=1` in the k-means method, and don't rescale the data.\n",
    "\n",
    "- 2\n",
    "- 3\n",
    "- ##### 4\n",
    "- 5\n",
    "\n",
    "In this case, we are looking for the most significant curve fracture on the `Cluster number vs Centroid distances` graph. Consider the number of clusters from 2 to 10. Use `random_state=1` for the k-means algorithm initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "inertia = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1).fit(X)\n",
    "    inertia.append(np.sqrt(kmeans.inertia_))\n",
    "\n",
    "plt.plot(range(2, 10), inertia, marker='s');\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('$J(C_k)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to the faces dataset. Imagine that we did not know the names for who was each photo but that we knew that there were 12 different people. Let's compare clustering results from 4 algorithms - k-means, Agglomerative clustering, Affinity Propagation, and Spectral clustering. Use the same respective parameters as in the end of lesson article, only change the number of clusters to 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, SpectralClustering\n",
    "\n",
    "X, y = scaled_data, lfw_people.target\n",
    "\n",
    "algorithms = []\n",
    "algorithms.append(KMeans(n_clusters=12, random_state=1))\n",
    "algorithms.append(AffinityPropagation())\n",
    "algorithms.append(SpectralClustering(n_clusters=12, random_state=1,\n",
    "                                     affinity='nearest_neighbors'))\n",
    "algorithms.append(AgglomerativeClustering(n_clusters=12))\n",
    "\n",
    "data = []\n",
    "for algo in algorithms:\n",
    "    algo.fit(X)\n",
    "    data.append(({\n",
    "        'ARI': metrics.adjusted_rand_score(y, algo.labels_),\n",
    "        'AMI': metrics.adjusted_mutual_info_score(y, algo.labels_),\n",
    "        'Homogenity': metrics.homogeneity_score(y, algo.labels_),\n",
    "        'Completeness': metrics.completeness_score(y, algo.labels_),\n",
    "        'V-measure': metrics.v_measure_score(y, algo.labels_),\n",
    "        'Silhouette': metrics.silhouette_score(X, algo.labels_)}))\n",
    "\n",
    "results = pd.DataFrame(data=data, columns=['ARI', 'AMI', 'Homogenity',\n",
    "                                           'Completeness', 'V-measure', \n",
    "                                           'Silhouette'],\n",
    "                       index=['K-means', 'Affinity', \n",
    "                              'Spectral', 'Agglomerative'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2 = (lfw_people.target == 10).astype(int)\n",
    "algorithms = []\n",
    "algorithms.append(KMeans(n_clusters=2, random_state=1))\n",
    "algorithms.append(AffinityPropagation())\n",
    "algorithms.append(SpectralClustering(n_clusters=2, random_state=1,\n",
    "                                     affinity='nearest_neighbors'))\n",
    "algorithms.append(AgglomerativeClustering(n_clusters=2))\n",
    "\n",
    "data = []\n",
    "for algo in algorithms:\n",
    "    algo.fit(X)\n",
    "    data.append(({\n",
    "        'ARI': metrics.adjusted_rand_score(y2, algo.labels_),\n",
    "        'AMI': metrics.adjusted_mutual_info_score(y2, algo.labels_),\n",
    "        'Homogenity': metrics.homogeneity_score(y2, algo.labels_),\n",
    "        'Completeness': metrics.completeness_score(y2, algo.labels_),\n",
    "        'V-measure': metrics.v_measure_score(y2, algo.labels_),\n",
    "        'Silhouette': metrics.silhouette_score(X, algo.labels_)}))\n",
    "\n",
    "results = pd.DataFrame(data=data, columns=['ARI', 'AMI', 'Homogenity',\n",
    "                                           'Completeness', 'V-measure', \n",
    "                                           'Silhouette'],\n",
    "                       index=['K-means', 'Affinity', \n",
    "                              'Spectral', 'Agglomerative'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8. </font> Select all of the correct statements:\n",
    "\n",
    "- Agglomerative clustering worked better than others by all metrics\n",
    "- ##### Clustering results are disappointing - there isn't a metric that exceeds 35%\n",
    "- ##### Affinity Propagation worked better than Spectral clustering by all metrics\n",
    "- Considering only 2 clusters (whether it is Serena Williams or not) and comparing clustering results with a binary vector, we can see that clustering algorithms work better, with some metrics exceeding 66%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the coordinates of the 12 \"average\" people's images you got before. Draw a dendrogram for them. Use `scipy.cluster.hierarchy` and `scipy.spatial.distance.pdist`, take parameters values from the appropriate example in the [article](https://habrahabr.ru/company/ods/blog/325654/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "\n",
    "distance_mat = pdist(vectors) # pdist посчитает нам верхний треугольник матрицы попарных расстояний\n",
    "\n",
    "Z = hierarchy.linkage(distance_mat, 'single') # linkage — реализация агломеративного алгоритма\n",
    "plt.figure(figsize=(10, 5))\n",
    "dn = hierarchy.dendrogram(Z, color_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lfw_people.target_names[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9. What person corresponds to the point that, according to the dendrogram, is connected with all but the last one?\n",
    "\n",
    "- Gerhard Schroeder\n",
    "- ##### Jean Chretien\n",
    "- John Ashcroft\n",
    "- Junichiro Koizumi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
