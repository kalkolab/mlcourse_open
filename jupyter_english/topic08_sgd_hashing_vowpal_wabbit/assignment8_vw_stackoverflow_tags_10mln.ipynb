{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Assignment № 8\n",
    "## <center> Vowpal Wabbit for Stackoverflow question tag classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "    1. Introduction\n",
    "    2. Data description\n",
    "    3. Data preprocessing\n",
    "    4. Training and validation of models\n",
    "    5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "In this task, you will do something that we do every week at Mail.Ru Group: train models on several GBs of data. You might cope with Python in Windows, but we strongly recommend some \\*NIX-system (for instance, with Docker) and use bash utils.\n",
    "A sad, but true, fact is that, if you want to work in the best companies in the world in ML, you will need experience with UNIX bash. Here is an interactive [tutorial](https://www.codecademy.com/en/courses/learn-the-command-line/lessons/environment/exercises/bash-profile) from CodeAcademy on UNIX command line (1-2 hours).\n",
    "\n",
    "Submit your answers through the [web-form](https://docs.google.com/forms/d/14adHGB-XKtpHlG9JJgog3DUzMUabd4y1YWG3b866m54/edit).\n",
    "\n",
    "For this particular task, you will need Vowpal Wabbit installed (we already have it inside the docker-container of our course. Check out instructions in the README in our course [repo](https://github.com/Yorko/mlcourse_open)). Make sure you have approximately 70 GB of disk space. I have tested the solution on an ordinary Macbook Pro 2015 (8 kernels, 16GB RAM), and the heaviest model was trained in ~ 12 min, so this task is doable with ordinary hardware. Still, if you have plans to rent Amazon servers, right now is a good time to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 10 GB of questions from StackOverflow – [download](https://drive.google.com/file/d/1ZU4J3KhJDrHVMj48fROFcTsTZKorPGlG/view) and unpack the archive. \n",
    "\n",
    "The data format is simple:<br>\n",
    "<center>*question text* (space dilimited words) TAB *question tags* (space delimited)\n",
    "\n",
    "TAB is the tabulation symbol.\n",
    "Let's see the first sample from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"../../raw_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 $PATH_TO_DATA/stackoverflow.10kk.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have the question text, followed by a tab and the question tags: *css, css3* and *css-selectors*. There are 10 billion of such questions in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!wc -l $PATH_TO_DATA/stackoverflow.10kk.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that we do not want to overload memory with this amount of data, so we will use the following Unix utilities - `head`, `tail`, `wc`, `cat`, `cut`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select all questions with the tags *javascript, java, python, ruby, php, c++, c#, go, scala*, and *swift* from the data source, and prepare the training set in Vowpal Wabbit's data format. We will perform 10-class question classification over the tags we've selected.\n",
    "\n",
    "In general, questions may have several tags, but we will simplify our task by selecting only one of the listed tags or dropping questions in case of no such tags.\n",
    "Note that VW supports multilabel classification (`--multilabel_oaa` parameter).\n",
    "<br>\n",
    "<br>\n",
    "Implement your data preprocessing code in a separate file `preprocess.py`. Your code must select lines with our tags and write them to a separate file in Vowpal Wabbit format. Details are as follows:\n",
    " - script must work with command line arguments: file paths for input and output\n",
    " - lines are processed one-by-one (there is a wonderful `tqdm` module for iterations counting)\n",
    " - if a line has no tab symbols or more than one tab symbol - then the line is broken, skip it\n",
    " - if a line has exactly one tab symbol, check how many tags are from our list *javascript, java, python, ruby, php, c++, c#, go, scala* or  *swift*. If there is only one tag, write the string to output with VW format: `label | text`, where `label` is a number from 1 to 10 (1 - *javascript*, ... 10 – *swift*). Skip strings with more than 1 or no tags.\n",
    " - remove `:` and `|` symbols from the question text - they have special meaning for VW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You should have 4389054 lines in the preprocessed data file. We can see that VW can process 10 GB of data in roughly 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess.py $PATH_TO_DATA/stackoverflow.10kk.tsv $PATH_TO_DATA/stackoverflow.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l $PATH_TO_DATA/stackoverflow.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation, and test sets in equal proportions with 1463018 lines in each file. We don't need to shuffle the data, the first 1463018 lines must go into training `stackoverflow_train.vw`, the last 1463018 lines to test `stackoverflow_test.vw`, and the rest to validation `stackoverflow_valid.vw`. \n",
    "\n",
    "Save answer vectors for validation and test sets into separate files: `stackoverflow_valid_labels.txt` and `stackoverflow_test_labels.txt`, respectively.\n",
    "\n",
    "Do not hesitate to use `head`, `tail`, `split`, `cat` and `cut` linux utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "!split -l 1463018 $PATH_TO_DATA/stackoverflow.vw stackoverflow_\n",
    "!mv stackoverflow_aa stackoverflow_train.vw\n",
    "!mv stackoverflow_ab stackoverflow_test.vw\n",
    "!mv stackoverflow_ac stackoverflow_valid.vw\n",
    "!cut -d'|' -f1 stackoverflow_valid.vw > stackoverflow_valid_labels.txt\n",
    "!cut -d'|' -f1 stackoverflow_test.vw > stackoverflow_test_labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training and validation of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Vowpal Wabbit with `stackoverflow_train.vw` 9 times with (1,3,5) iterating passes and n-gram (n=1,2,3) parameters.\n",
    "The rest of the parameters are `bit_precision=28` and `seed=17`. Don't forget to tell VW that we have a 10-class problem.\n",
    "\n",
    "Evaluate accuracy on `stackoverflow_valid.vw`. Choose the model with the best parameters, and test it on `stackoverflow_test.vw` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred\n",
       "0     1\n",
       "1     5\n",
       "2     7\n",
       "3     2\n",
       "4     9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = pd.read_csv('stackoverflow_valid_labels.txt', names=['pred'])\n",
    "y_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 1 --passes 1 -b 28 --random_seed 17 --readable_model 1_1readable.vw.model -f 1_1vw.model -c\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = 1_1vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        7        7      209\n",
      "0.781250 0.812500           32           32.0        7        2      174\n",
      "0.765625 0.750000           64           64.0        3        3      204\n",
      "0.648438 0.531250          128          128.0        1        5       29\n",
      "0.609375 0.570312          256          256.0        5        1      169\n",
      "0.548828 0.488281          512          512.0        2        2      303\n",
      "0.456055 0.363281         1024         1024.0        3        3      123\n",
      "0.375000 0.293945         2048         2048.0        1        5       83\n",
      "0.309082 0.243164         4096         4096.0        1        1       79\n",
      "0.261841 0.214600         8192         8192.0        2        2      112\n",
      "0.220825 0.179810        16384        16384.0        7        7      252\n",
      "0.186096 0.151367        32768        32768.0        4        5      134\n",
      "0.159149 0.132202        65536        65536.0        5        5      145\n",
      "0.138329 0.117508       131072       131072.0        7        2      255\n",
      "0.120888 0.103447       262144       262144.0        7        7      101\n",
      "0.108549 0.096210       524288       524288.0        1        1      818\n",
      "0.099817 0.091085      1048576      1048576.0        1        1      571\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.095764\n",
      "total feature number = 291954690\n",
      "vw -d stackoverflow_valid.vw -t -i 1_1vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      122\n",
      "0.000000 0.000000            2            2.0        5        5      187\n",
      "0.000000 0.000000            4            4.0        2        2      136\n",
      "0.125000 0.250000            8            8.0        5        5       80\n",
      "0.062500 0.000000           16           16.0        6        6      174\n",
      "0.062500 0.062500           32           32.0        2        2      649\n",
      "0.078125 0.093750           64           64.0        1        5       57\n",
      "0.085938 0.093750          128          128.0        1        1       92\n",
      "0.078125 0.070312          256          256.0        2        2       42\n",
      "0.072266 0.066406          512          512.0        5        5      152\n",
      "0.072266 0.072266         1024         1024.0        2        2      103\n",
      "0.077148 0.082031         2048         2048.0        6        6      148\n",
      "0.076904 0.076660         4096         4096.0        1        1      126\n",
      "0.079712 0.082520         8192         8192.0        1        1      201\n",
      "0.081543 0.083374        16384        16384.0        2        2      132\n",
      "0.083130 0.084717        32768        32768.0        6        6      170\n",
      "0.083313 0.083496        65536        65536.0        1        1     3000\n",
      "0.083023 0.082733       131072       131072.0        7        7      111\n",
      "0.082932 0.082840       262144       262144.0        7        7      114\n",
      "0.083136 0.083340       524288       524288.0        7        7      375\n",
      "0.083174 0.083212      1048576      1048576.0        7        2       25\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.083246\n",
      "total feature number = 292619465\n",
      "With 1 ngrams and 1 passes got 0.916754\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 1 --passes 3 -b 28 --random_seed 17 --readable_model 1_3readable.vw.model -f 1_3vw.model -c\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = 1_3vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        2        7      159\n",
      "0.750000 0.750000           32           32.0        1        7      404\n",
      "0.703125 0.656250           64           64.0        7        7      103\n",
      "0.617188 0.531250          128          128.0        5        5      276\n",
      "0.593750 0.570312          256          256.0        1        1      102\n",
      "0.533203 0.472656          512          512.0        2        5       68\n",
      "0.457031 0.380859         1024         1024.0        1        1      132\n",
      "0.383301 0.309570         2048         2048.0        7        7       71\n",
      "0.310059 0.236816         4096         4096.0        2        2      319\n",
      "0.262085 0.214111         8192         8192.0        5        5       24\n",
      "0.223450 0.184814        16384        16384.0        3        3      581\n",
      "0.185547 0.147644        32768        32768.0        3        3       28\n",
      "0.158493 0.131439        65536        65536.0        4        4      184\n",
      "0.137115 0.115738       131072       131072.0        2        2       95\n",
      "0.121109 0.105103       262144       262144.0        5        5      232\n",
      "0.108404 0.095699       524288       524288.0        6        6      142\n",
      "0.100007 0.091610      1048576      1048576.0        1        1      422\n",
      "0.092582 0.092582      2097152      2097152.0        5        5      696 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.084107 h\n",
      "total feature number = 788274150\n",
      "vw -d stackoverflow_valid.vw -t -i 1_3vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      122\n",
      "0.000000 0.000000            2            2.0        5        5      187\n",
      "0.000000 0.000000            4            4.0        2        2      136\n",
      "0.125000 0.250000            8            8.0        5        5       80\n",
      "0.062500 0.000000           16           16.0        6        6      174\n",
      "0.062500 0.062500           32           32.0        2        2      649\n",
      "0.078125 0.093750           64           64.0        1        5       57\n",
      "0.085938 0.093750          128          128.0        1        1       92\n",
      "0.078125 0.070312          256          256.0        2        2       42\n",
      "0.072266 0.066406          512          512.0        5        5      152\n",
      "0.069336 0.066406         1024         1024.0        2        2      103\n",
      "0.078613 0.087891         2048         2048.0        6        6      148\n",
      "0.077148 0.075684         4096         4096.0        1        1      126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.079224 0.081299         8192         8192.0        1        1      201\n",
      "0.080139 0.081055        16384        16384.0        2        2      132\n",
      "0.081635 0.083130        32768        32768.0        6        6      170\n",
      "0.081863 0.082092        65536        65536.0        1        1     3000\n",
      "0.081352 0.080841       131072       131072.0        7        7      111\n",
      "0.081676 0.082001       262144       262144.0        7        7      114\n",
      "0.081945 0.082214       524288       524288.0        7        7      375\n",
      "0.081896 0.081846      1048576      1048576.0        7        7       25\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.081903\n",
      "total feature number = 292619465\n",
      "With 1 ngrams and 3 passes got 0.918097\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 1 --passes 5 -b 28 --random_seed 17 --readable_model 1_5readable.vw.model -f 1_5vw.model -c\n",
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = 1_5vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      161\n",
      "0.500000 1.000000            2            2.0        4        1       68\n",
      "0.750000 1.000000            4            4.0        7        1       88\n",
      "0.750000 0.750000            8            8.0        7        1       95\n",
      "0.750000 0.750000           16           16.0        2        7      159\n",
      "0.750000 0.750000           32           32.0        1        7      404\n",
      "0.703125 0.656250           64           64.0        7        7      103\n",
      "0.617188 0.531250          128          128.0        5        5      276\n",
      "0.593750 0.570312          256          256.0        1        1      102\n",
      "0.533203 0.472656          512          512.0        2        5       68\n",
      "0.457031 0.380859         1024         1024.0        1        1      132\n",
      "0.383301 0.309570         2048         2048.0        7        7       71\n",
      "0.310059 0.236816         4096         4096.0        2        2      319\n",
      "0.262085 0.214111         8192         8192.0        5        5       24\n",
      "0.223450 0.184814        16384        16384.0        3        3      581\n",
      "0.185547 0.147644        32768        32768.0        3        3       28\n",
      "0.158493 0.131439        65536        65536.0        4        4      184\n",
      "0.137115 0.115738       131072       131072.0        2        2       95\n",
      "0.121109 0.105103       262144       262144.0        5        5      232\n",
      "0.108404 0.095699       524288       524288.0        6        6      142\n",
      "0.100007 0.091610      1048576      1048576.0        1        1      422\n",
      "0.092582 0.092582      2097152      2097152.0        5        5      696 h\n",
      "0.088155 0.083728      4194304      4194304.0        1        1      216 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.083287 h\n",
      "total feature number = 1313790250\n",
      "vw -d stackoverflow_valid.vw -t -i 1_5vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      122\n",
      "0.000000 0.000000            2            2.0        5        5      187\n",
      "0.000000 0.000000            4            4.0        2        2      136\n",
      "0.125000 0.250000            8            8.0        5        5       80\n",
      "0.062500 0.000000           16           16.0        6        6      174\n",
      "0.062500 0.062500           32           32.0        2        2      649\n",
      "0.078125 0.093750           64           64.0        1        5       57\n",
      "0.085938 0.093750          128          128.0        1        1       92\n",
      "0.074219 0.062500          256          256.0        2        2       42\n",
      "0.070312 0.066406          512          512.0        5        5      152\n",
      "0.072266 0.074219         1024         1024.0        2        2      103\n",
      "0.079102 0.085938         2048         2048.0        6        6      148\n",
      "0.078857 0.078613         4096         4096.0        1        1      126\n",
      "0.079834 0.080811         8192         8192.0        1        1      201\n",
      "0.080811 0.081787        16384        16384.0        2        2      132\n",
      "0.082428 0.084045        32768        32768.0        6        6      170\n",
      "0.082016 0.081604        65536        65536.0        1        1     3000\n",
      "0.081940 0.081863       131072       131072.0        7        7      111\n",
      "0.082077 0.082214       262144       262144.0        7        7      114\n",
      "0.082058 0.082039       524288       524288.0        7        7      375\n",
      "0.081933 0.081808      1048576      1048576.0        7        5       25\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.081966\n",
      "total feature number = 292619465\n",
      "With 1 ngrams and 5 passes got 0.918034\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 2 --passes 1 -b 28 --random_seed 17 --readable_model 2_1readable.vw.model -f 2_1vw.model -c\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = 2_1vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        7        7      416\n",
      "0.781250 0.812500           32           32.0        7        2      346\n",
      "0.750000 0.718750           64           64.0        3        3      406\n",
      "0.648438 0.546875          128          128.0        1        7       56\n",
      "0.617188 0.585938          256          256.0        5        1      336\n",
      "0.548828 0.480469          512          512.0        2        2      604\n",
      "0.454102 0.359375         1024         1024.0        3        3      244\n",
      "0.375000 0.295898         2048         2048.0        1        5      164\n",
      "0.306396 0.237793         4096         4096.0        1        1      156\n",
      "0.254761 0.203125         8192         8192.0        2        2      222\n",
      "0.211426 0.168091        16384        16384.0        7        7      502\n",
      "0.176117 0.140808        32768        32768.0        4        5      266\n",
      "0.147873 0.119629        65536        65536.0        5        5      288\n",
      "0.126411 0.104950       131072       131072.0        7        2      508\n",
      "0.108402 0.090393       262144       262144.0        7        7      200\n",
      "0.097092 0.085781       524288       524288.0        1        1     1634\n",
      "0.086005 0.074919      1048576      1048576.0        1        1     1140\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.081809\n",
      "total feature number = 580983344\n",
      "vw -d stackoverflow_valid.vw -t -i 2_1vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      242\n",
      "0.000000 0.000000            2            2.0        5        5      372\n",
      "0.250000 0.500000            4            4.0        2        2      270\n",
      "0.250000 0.250000            8            8.0        5        5      158\n",
      "0.187500 0.125000           16           16.0        6        6      346\n",
      "0.125000 0.062500           32           32.0        2        2     1296\n",
      "0.093750 0.062500           64           64.0        1        5      112\n",
      "0.085938 0.078125          128          128.0        1        1      182\n",
      "0.070312 0.054688          256          256.0        2        1       82\n",
      "0.072266 0.074219          512          512.0        5        5      302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059570 0.046875         1024         1024.0        2        2      204\n",
      "0.065918 0.072266         2048         2048.0        6        6      294\n",
      "0.069580 0.073242         4096         4096.0        1        1      250\n",
      "0.067383 0.065186         8192         8192.0        1        1      400\n",
      "0.067017 0.066650        16384        16384.0        2        2      262\n",
      "0.067810 0.068604        32768        32768.0        6        6      338\n",
      "0.068176 0.068542        65536        65536.0        1        1     5998\n",
      "0.067429 0.066681       131072       131072.0        7        7      220\n",
      "0.067318 0.067207       262144       262144.0        7        7      226\n",
      "0.067663 0.068008       524288       524288.0        7        7      748\n",
      "0.067591 0.067518      1048576      1048576.0        7        2       48\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.067465\n",
      "total feature number = 582312894\n",
      "With 2 ngrams and 1 passes got 0.932535\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 2 --passes 3 -b 28 --random_seed 17 --readable_model 2_3readable.vw.model -f 2_3vw.model -c\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = 2_3vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        2        7      316\n",
      "0.718750 0.687500           32           32.0        1        7      806\n",
      "0.703125 0.687500           64           64.0        7        7      204\n",
      "0.632812 0.562500          128          128.0        5        5      550\n",
      "0.609375 0.585938          256          256.0        1        1      202\n",
      "0.531250 0.453125          512          512.0        2        5      134\n",
      "0.458984 0.386719         1024         1024.0        1        1      262\n",
      "0.382812 0.306641         2048         2048.0        7        7      140\n",
      "0.305664 0.228516         4096         4096.0        2        2      636\n",
      "0.255249 0.204834         8192         8192.0        5        7       46\n",
      "0.215027 0.174805        16384        16384.0        3        3     1160\n",
      "0.177612 0.140198        32768        32768.0        3        3       54\n",
      "0.148590 0.119568        65536        65536.0        4        4      366\n",
      "0.127281 0.105972       131072       131072.0        2        2      188\n",
      "0.110416 0.093552       262144       262144.0        5        5      462\n",
      "0.096605 0.082794       524288       524288.0        6        6      282\n",
      "0.086320 0.076035      1048576      1048576.0        1        1      842\n",
      "0.077806 0.077806      2097152      2097152.0        5        5     1390 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.069835 h\n",
      "total feature number = 1568647998\n",
      "vw -d stackoverflow_valid.vw -t -i 2_3vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      242\n",
      "0.000000 0.000000            2            2.0        5        5      372\n",
      "0.250000 0.500000            4            4.0        2        2      270\n",
      "0.125000 0.000000            8            8.0        5        5      158\n",
      "0.062500 0.000000           16           16.0        6        6      346\n",
      "0.062500 0.062500           32           32.0        2        2     1296\n",
      "0.062500 0.062500           64           64.0        1        5      112\n",
      "0.062500 0.062500          128          128.0        1        1      182\n",
      "0.062500 0.062500          256          256.0        2        1       82\n",
      "0.068359 0.074219          512          512.0        5        5      302\n",
      "0.065430 0.062500         1024         1024.0        2        2      204\n",
      "0.069336 0.073242         2048         2048.0        6        6      294\n",
      "0.069092 0.068848         4096         4096.0        1        1      250\n",
      "0.069092 0.069092         8192         8192.0        1        1      400\n",
      "0.067993 0.066895        16384        16384.0        2        2      262\n",
      "0.069672 0.071350        32768        32768.0        6        6      338\n",
      "0.070175 0.070679        65536        65536.0        1        1     5998\n",
      "0.069542 0.068909       131072       131072.0        7        7      220\n",
      "0.069534 0.069527       262144       262144.0        7        7      226\n",
      "0.069756 0.069977       524288       524288.0        7        7      748\n",
      "0.069633 0.069511      1048576      1048576.0        7        2       48\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.069456\n",
      "total feature number = 582312894\n",
      "With 2 ngrams and 3 passes got 0.930544\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 2 --passes 5 -b 28 --random_seed 17 --readable_model 2_5readable.vw.model -f 2_5vw.model -c\n",
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = 2_5vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        2        7      316\n",
      "0.718750 0.687500           32           32.0        1        7      806\n",
      "0.703125 0.687500           64           64.0        7        7      204\n",
      "0.632812 0.562500          128          128.0        5        5      550\n",
      "0.609375 0.585938          256          256.0        1        1      202\n",
      "0.531250 0.453125          512          512.0        2        5      134\n",
      "0.458984 0.386719         1024         1024.0        1        1      262\n",
      "0.382812 0.306641         2048         2048.0        7        7      140\n",
      "0.305664 0.228516         4096         4096.0        2        2      636\n",
      "0.255249 0.204834         8192         8192.0        5        7       46\n",
      "0.215027 0.174805        16384        16384.0        3        3     1160\n",
      "0.177612 0.140198        32768        32768.0        3        3       54\n",
      "0.148590 0.119568        65536        65536.0        4        4      366\n",
      "0.127281 0.105972       131072       131072.0        2        2      188\n",
      "0.110416 0.093552       262144       262144.0        5        5      462\n",
      "0.096605 0.082794       524288       524288.0        6        6      282\n",
      "0.086320 0.076035      1048576      1048576.0        1        1      842\n",
      "0.077806 0.077806      2097152      2097152.0        5        5     1390 h\n",
      "0.073817 0.069828      4194304      4194304.0        1        1      430 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.069835 h\n",
      "total feature number = 2614413330\n",
      "vw -d stackoverflow_valid.vw -t -i 2_5vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      242\n",
      "0.000000 0.000000            2            2.0        5        5      372\n",
      "0.250000 0.500000            4            4.0        2        2      270\n",
      "0.125000 0.000000            8            8.0        5        5      158\n",
      "0.125000 0.125000           16           16.0        6        6      346\n",
      "0.093750 0.062500           32           32.0        2        2     1296\n",
      "0.078125 0.062500           64           64.0        1        5      112\n",
      "0.078125 0.078125          128          128.0        1        1      182\n",
      "0.070312 0.062500          256          256.0        2        1       82\n",
      "0.072266 0.074219          512          512.0        5        5      302\n",
      "0.063477 0.054688         1024         1024.0        2        2      204\n",
      "0.067871 0.072266         2048         2048.0        6        6      294\n",
      "0.068848 0.069824         4096         4096.0        1        1      250\n",
      "0.067993 0.067139         8192         8192.0        1        1      400\n",
      "0.068115 0.068237        16384        16384.0        2        2      262\n",
      "0.068878 0.069641        32768        32768.0        6        6      338\n",
      "0.069519 0.070160        65536        65536.0        1        1     5998\n",
      "0.068810 0.068100       131072       131072.0        7        7      220\n",
      "0.069118 0.069427       262144       262144.0        7        7      226\n",
      "0.069132 0.069145       524288       524288.0        7        7      748\n",
      "0.069002 0.068872      1048576      1048576.0        7        2       48\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.068798\n",
      "total feature number = 582312894\n",
      "With 2 ngrams and 5 passes got 0.931202\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 3 --passes 1 -b 28 --random_seed 17 --readable_model 3_1readable.vw.model -f 3_1vw.model -c\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = 3_1vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        7        7      622\n",
      "0.781250 0.812500           32           32.0        7        2      517\n",
      "0.750000 0.718750           64           64.0        3        3      607\n",
      "0.648438 0.546875          128          128.0        1        7       82\n",
      "0.628906 0.609375          256          256.0        5        1      502\n",
      "0.564453 0.500000          512          512.0        2        2      904\n",
      "0.471680 0.378906         1024         1024.0        3        3      364\n",
      "0.400879 0.330078         2048         2048.0        1        5      244\n",
      "0.333252 0.265625         4096         4096.0        1        1      232\n",
      "0.281006 0.228760         8192         8192.0        2        2      331\n",
      "0.232361 0.183716        16384        16384.0        7        7      751\n",
      "0.192169 0.151978        32768        32768.0        4        5      397\n",
      "0.160690 0.129211        65536        65536.0        5        5      430\n",
      "0.136086 0.111481       131072       131072.0        7        2      760\n",
      "0.115993 0.095901       262144       262144.0        7        7      298\n",
      "0.102705 0.089417       524288       524288.0        1        1     2449\n",
      "0.090337 0.077969      1048576      1048576.0        1        1     1708\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.085885\n",
      "total feature number = 868548985\n",
      "vw -d stackoverflow_valid.vw -t -i 3_1vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      361\n",
      "0.000000 0.000000            2            2.0        5        5      556\n",
      "0.000000 0.000000            4            4.0        2        2      403\n",
      "0.000000 0.000000            8            8.0        5        5      235\n",
      "0.062500 0.125000           16           16.0        6        6      517\n",
      "0.062500 0.062500           32           32.0        2        2     1942\n",
      "0.062500 0.062500           64           64.0        1        5      166\n",
      "0.085938 0.109375          128          128.0        1        1      271\n",
      "0.089844 0.093750          256          256.0        2        1      121\n",
      "0.082031 0.074219          512          512.0        5        5      451\n",
      "0.073242 0.064453         1024         1024.0        2        2      304\n",
      "0.076660 0.080078         2048         2048.0        6        6      439\n",
      "0.075195 0.073730         4096         4096.0        1        1      373\n",
      "0.072388 0.069580         8192         8192.0        1        1      598\n",
      "0.071472 0.070557        16384        16384.0        2        2      391\n",
      "0.071625 0.071777        32768        32768.0        6        6      505\n",
      "0.071747 0.071869        65536        65536.0        1        1     8995\n",
      "0.070839 0.069931       131072       131072.0        7        7      328\n",
      "0.070099 0.069359       262144       262144.0        7        7      337\n",
      "0.070360 0.070621       524288       524288.0        7        7     1120\n",
      "0.070247 0.070133      1048576      1048576.0        7        2       70\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.070122\n",
      "total feature number = 870543306\n",
      "With 3 ngrams and 1 passes got 0.929878\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 3 --passes 3 -b 28 --random_seed 17 --readable_model 3_3readable.vw.model -f 3_3vw.model -c\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = 3_3vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        2        7      472\n",
      "0.718750 0.687500           32           32.0        1        7     1207\n",
      "0.687500 0.656250           64           64.0        7        7      304\n",
      "0.640625 0.593750          128          128.0        5        1      823\n",
      "0.625000 0.609375          256          256.0        1        1      301\n",
      "0.544922 0.464844          512          512.0        2        1      199\n",
      "0.466797 0.388672         1024         1024.0        1        1      391\n",
      "0.402344 0.337891         2048         2048.0        7        7      208\n",
      "0.328125 0.253906         4096         4096.0        2        2      952\n",
      "0.279419 0.230713         8192         8192.0        5        2       67\n",
      "0.232727 0.186035        16384        16384.0        3        3     1738\n",
      "0.191132 0.149536        32768        32768.0        3        3       79\n",
      "0.159424 0.127716        65536        65536.0        4        4      547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135880 0.112335       131072       131072.0        2        2      280\n",
      "0.117374 0.098869       262144       262144.0        5        5      691\n",
      "0.102125 0.086876       524288       524288.0        6        6      421\n",
      "0.090308 0.078491      1048576      1048576.0        1        1     1261\n",
      "0.081231 0.081231      2097152      2097152.0        5        5     2083 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 3\n",
      "weighted example sum = 3950151.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.073110 h\n",
      "total feature number = 2345071710\n",
      "vw -d stackoverflow_valid.vw -t -i 3_3vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      361\n",
      "0.000000 0.000000            2            2.0        5        5      556\n",
      "0.000000 0.000000            4            4.0        2        2      403\n",
      "0.000000 0.000000            8            8.0        5        5      235\n",
      "0.000000 0.000000           16           16.0        6        6      517\n",
      "0.031250 0.062500           32           32.0        2        2     1942\n",
      "0.046875 0.062500           64           64.0        1        5      166\n",
      "0.062500 0.078125          128          128.0        1        1      271\n",
      "0.074219 0.085938          256          256.0        2        1      121\n",
      "0.076172 0.078125          512          512.0        5        5      451\n",
      "0.072266 0.068359         1024         1024.0        2        2      304\n",
      "0.076172 0.080078         2048         2048.0        6        6      439\n",
      "0.074463 0.072754         4096         4096.0        1        1      373\n",
      "0.073364 0.072266         8192         8192.0        1        1      598\n",
      "0.073303 0.073242        16384        16384.0        2        2      391\n",
      "0.074005 0.074707        32768        32768.0        6        6      505\n",
      "0.074203 0.074402        65536        65536.0        1        1     8995\n",
      "0.073288 0.072372       131072       131072.0        7        7      328\n",
      "0.073036 0.072784       262144       262144.0        7        7      337\n",
      "0.073133 0.073231       524288       524288.0        7        7     1120\n",
      "0.073138 0.073143      1048576      1048576.0        7        2       70\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.072841\n",
      "total feature number = 870543306\n",
      "With 3 ngrams and 3 passes got 0.927159\n",
      "vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram 3 --passes 5 -b 28 --random_seed 17 --readable_model 3_5readable.vw.model -f 3_5vw.model -c\n",
      "Generating 3-grams for all namespaces.\n",
      "final_regressor = 3_5vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "using cache_file = stackoverflow_train.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      478\n",
      "0.500000 1.000000            2            2.0        4        1      199\n",
      "0.750000 1.000000            4            4.0        7        1      259\n",
      "0.750000 0.750000            8            8.0        7        1      280\n",
      "0.750000 0.750000           16           16.0        2        7      472\n",
      "0.718750 0.687500           32           32.0        1        7     1207\n",
      "0.687500 0.656250           64           64.0        7        7      304\n",
      "0.640625 0.593750          128          128.0        5        1      823\n",
      "0.625000 0.609375          256          256.0        1        1      301\n",
      "0.544922 0.464844          512          512.0        2        1      199\n",
      "0.466797 0.388672         1024         1024.0        1        1      391\n",
      "0.402344 0.337891         2048         2048.0        7        7      208\n",
      "0.328125 0.253906         4096         4096.0        2        2      952\n",
      "0.279419 0.230713         8192         8192.0        5        2       67\n",
      "0.232727 0.186035        16384        16384.0        3        3     1738\n",
      "0.191132 0.149536        32768        32768.0        3        3       79\n",
      "0.159424 0.127716        65536        65536.0        4        4      547\n",
      "0.135880 0.112335       131072       131072.0        2        2      280\n",
      "0.117374 0.098869       262144       262144.0        5        5      691\n",
      "0.102125 0.086876       524288       524288.0        6        6      421\n",
      "0.090308 0.078491      1048576      1048576.0        1        1     1261\n",
      "0.081231 0.081231      2097152      2097152.0        5        5     2083 h\n",
      "0.077415 0.073600      4194304      4194304.0        1        1      643 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1316717\n",
      "passes used = 5\n",
      "weighted example sum = 6583585.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.073110 h\n",
      "total feature number = 3908452850\n",
      "vw -d stackoverflow_valid.vw -t -i 3_5vw.model -p stackoverflow_valid_preds.txt\n",
      "Generating 3-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      361\n",
      "0.000000 0.000000            2            2.0        5        5      556\n",
      "0.000000 0.000000            4            4.0        2        2      403\n",
      "0.000000 0.000000            8            8.0        5        5      235\n",
      "0.062500 0.125000           16           16.0        6        6      517\n",
      "0.062500 0.062500           32           32.0        2        2     1942\n",
      "0.062500 0.062500           64           64.0        1        5      166\n",
      "0.062500 0.062500          128          128.0        1        1      271\n",
      "0.074219 0.085938          256          256.0        2        1      121\n",
      "0.076172 0.078125          512          512.0        5        5      451\n",
      "0.074219 0.072266         1024         1024.0        2        2      304\n",
      "0.076172 0.078125         2048         2048.0        6        6      439\n",
      "0.073486 0.070801         4096         4096.0        1        1      373\n",
      "0.072754 0.072021         8192         8192.0        1        1      598\n",
      "0.072510 0.072266        16384        16384.0        2        2      391\n",
      "0.073395 0.074280        32768        32768.0        6        6      505\n",
      "0.073639 0.073883        65536        65536.0        1        1     8995\n",
      "0.072670 0.071701       131072       131072.0        7        7      328\n",
      "0.072289 0.071907       262144       262144.0        7        7      337\n",
      "0.072346 0.072403       524288       524288.0        7        7     1120\n",
      "0.072209 0.072073      1048576      1048576.0        7        2       70\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.071917\n",
      "total feature number = 870543306\n",
      "With 3 ngrams and 5 passes got 0.928083\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "settings = []\n",
    "for ngram in [1, 2, 3]:\n",
    "    for passes in [1,3,5]:\n",
    "        train_cmd = \"vw -d stackoverflow_train.vw --loss_function hinge --oaa 10 --ngram {ng} --passes {ps} \\\n",
    "        -b 28 --random_seed 17 --readable_model {ng}_{ps}readable.vw.model -f {ng}_{ps}vw.model -c\".format(ng=ngram, ps=passes)\n",
    "        ! echo $train_cmd\n",
    "        ! $train_cmd\n",
    "        test_cmd = \"vw -d stackoverflow_valid.vw -t -i {ng}_{ps}vw.model -p stackoverflow_valid_preds.txt\".format(ng=ngram, ps=passes)\n",
    "        ! echo $test_cmd\n",
    "        ! $test_cmd\n",
    "        y_pred = pd.read_csv('stackoverflow_valid_preds.txt', names=['pred'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        accuracies.append(acc)\n",
    "        settings.append(\"n%d p%d\" % (ngram, passes))\n",
    "        print(\"With %d ngrams and %d passes got %f\" % (ngram, passes, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(settings,accuracies)))\n",
    "print(settings[np.argmax(accuracies)])\n",
    "acc_valid_max = max(accuracies)\n",
    "print(acc_valid_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args =  -d stackoverflow_valid.vw -t --initial_regressor 2_1vw.model -p stackoverflow_valid_preds.txt --loss_function hinge --oaa 10 --ngram 2 --passes 1 -b 28 --random_seed 17 --bit_precision 28 --ngram 2 --hash_seed 0 --oaa 10 --link identity\n",
      "ignoring duplicate option: '--bit_precision 28'\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_valid_preds.txt\n",
      "args =  -d stackoverflow_valid.vw --testonly --initial_regressor 2_1vw.model --predictions stackoverflow_valid_preds.txt --loss_function hinge --oaa 10 --ngram 2 --passes 1 --bit_precision 28 --random_seed 17 --ngram 2 --hash_seed 0 --oaa 10 --link identity\n",
      "ignoring duplicate option: '--oaa 10'\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      242\n",
      "0.000000 0.000000            2            2.0        5        5      372\n",
      "0.250000 0.500000            4            4.0        2        2      270\n",
      "0.250000 0.250000            8            8.0        5        5      158\n",
      "0.187500 0.125000           16           16.0        6        6      346\n",
      "0.125000 0.062500           32           32.0        2        2     1296\n",
      "0.093750 0.062500           64           64.0        1        5      112\n",
      "0.085938 0.078125          128          128.0        1        1      182\n",
      "0.070312 0.054688          256          256.0        2        1       82\n",
      "0.072266 0.074219          512          512.0        5        5      302\n",
      "0.059570 0.046875         1024         1024.0        2        2      204\n",
      "0.065918 0.072266         2048         2048.0        6        6      294\n",
      "0.069580 0.073242         4096         4096.0        1        1      250\n",
      "0.067383 0.065186         8192         8192.0        1        1      400\n",
      "0.067017 0.066650        16384        16384.0        2        2      262\n",
      "0.067810 0.068604        32768        32768.0        6        6      338\n",
      "0.068176 0.068542        65536        65536.0        1        1     5998\n",
      "0.067429 0.066681       131072       131072.0        7        7      220\n",
      "0.067318 0.067207       262144       262144.0        7        7      226\n",
      "0.067663 0.068008       524288       524288.0        7        7      748\n",
      "0.067591 0.067518      1048576      1048576.0        7        2       48\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.067465\n",
      "total feature number = 582312894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9325346646452743"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!vw -d stackoverflow_valid.vw -t -i 2_1vw.model -p stackoverflow_valid_preds.txt --loss_function hinge --ngram 2 --passes 1 --random_seed 17\n",
    "y_pred = pd.read_csv('stackoverflow_valid_preds.txt', names=['pred'])\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Which parameter set provides the best accuracy on the validation set `stackoverflow_valid.vw`?\n",
    "- bigrams and 3 passes\n",
    "- trigrams and 5 passes\n",
    "- ##### bigrams and 1 pass\n",
    "- unigrams and 1 pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the best (according to validation accuracy) model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw -d stackoverflow_test.vw -t -i 2_1vw.model -p stackoverflow_test_preds.txt --loss_function hinge --ngram 2 --passes 1 --random_seed 17\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_test_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        2        7      354\n",
      "0.500000 0.000000            2            2.0        7        7      146\n",
      "0.250000 0.000000            4            4.0        5        5      516\n",
      "0.125000 0.000000            8            8.0        7        7      286\n",
      "0.125000 0.125000           16           16.0        6        6      716\n",
      "0.062500 0.000000           32           32.0        2        2      798\n",
      "0.062500 0.062500           64           64.0        5        5     2120\n",
      "0.046875 0.031250          128          128.0        2        2      262\n",
      "0.074219 0.101562          256          256.0        6        6      174\n",
      "0.060547 0.046875          512          512.0        7        7       68\n",
      "0.056641 0.052734         1024         1024.0        1        1      174\n",
      "0.061523 0.066406         2048         2048.0        2        2      484\n",
      "0.062500 0.063477         4096         4096.0        2        2      524\n",
      "0.065918 0.069336         8192         8192.0        7        7      542\n",
      "0.067444 0.068970        16384        16384.0        2        2      252\n",
      "0.067261 0.067078        32768        32768.0        1        1      240\n",
      "0.068024 0.068787        65536        65536.0        2        2      148\n",
      "0.067589 0.067154       131072       131072.0        2        2       30\n",
      "0.067104 0.066620       262144       262144.0        6        6      162\n",
      "0.067429 0.067753       524288       524288.0        5        5      644\n",
      "0.067744 0.068060      1048576      1048576.0        4        2      210\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.067645\n",
      "total feature number = 580609416\n",
      "0.9323548992561951\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "y_true_test = pd.read_csv('stackoverflow_test_labels.txt', names=['pred'])\n",
    "test_cmd = \"vw -d stackoverflow_test.vw -t -i 2_1vw.model -p stackoverflow_test_preds.txt --loss_function hinge --ngram 2 --passes 1 --random_seed 17\"\n",
    "! echo $test_cmd\n",
    "! $test_cmd\n",
    "y_pred = pd.read_csv('stackoverflow_test_preds.txt', names=['pred'])\n",
    "acc_test = accuracy_score(y_true_test, y_pred)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01797653890792672"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_test-acc_valid_max)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Compare best validation and test accuracies. Choose the correct answer (% is a percent here i.e. a drop from 50% to 40% would be 10%, not 20%).\n",
    "- Test accuracy is lower by approx. 2%\n",
    "- Test accuracy is lower by approx. 3%\n",
    "- ##### difference is less than 0.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train VW with parameters selected on the validation set, but first merge the training and validation sets. Evaluate the share of correct answers on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "!cat stackoverflow_train.vw stackoverflow_valid.vw > stackoverflow_train_big.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for all namespaces.\n",
      "final_regressor = vw.model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using cache_file = stackoverflow_train_big.vw.cache\n",
      "ignoring text input in favor of cache input\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      320\n",
      "0.500000 1.000000            2            2.0        4        1      134\n",
      "0.750000 1.000000            4            4.0        7        1      174\n",
      "0.750000 0.750000            8            8.0        7        1      188\n",
      "0.750000 0.750000           16           16.0        7        7      416\n",
      "0.781250 0.812500           32           32.0        7        2      346\n",
      "0.750000 0.718750           64           64.0        3        3      406\n",
      "0.648438 0.546875          128          128.0        1        7       56\n",
      "0.617188 0.585938          256          256.0        5        1      336\n",
      "0.548828 0.480469          512          512.0        2        2      604\n",
      "0.454102 0.359375         1024         1024.0        3        3      244\n",
      "0.375000 0.295898         2048         2048.0        1        5      164\n",
      "0.306396 0.237793         4096         4096.0        1        1      156\n",
      "0.254761 0.203125         8192         8192.0        2        2      222\n",
      "0.211426 0.168091        16384        16384.0        7        7      502\n",
      "0.176117 0.140808        32768        32768.0        4        5      266\n",
      "0.147873 0.119629        65536        65536.0        5        5      288\n",
      "0.126411 0.104950       131072       131072.0        7        2      508\n",
      "0.108402 0.090393       262144       262144.0        7        7      200\n",
      "0.097092 0.085781       524288       524288.0        1        1     1634\n",
      "0.086005 0.074919      1048576      1048576.0        1        1     1140\n",
      "0.077355 0.068705      2097152      2097152.0        1        1     1406\n",
      "\n",
      "finished run\n",
      "number of examples = 2926036\n",
      "weighted example sum = 2926036.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.073512\n",
      "total feature number = 1163296238\n",
      "Generating 2-grams for all namespaces.\n",
      "only testing\n",
      "predictions = stackoverflow_test_preds.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        2        7      354\n",
      "0.500000 0.000000            2            2.0        7        7      146\n",
      "0.250000 0.000000            4            4.0        5        5      516\n",
      "0.125000 0.000000            8            8.0        7        7      286\n",
      "0.062500 0.000000           16           16.0        6        6      716\n",
      "0.031250 0.000000           32           32.0        2        2      798\n",
      "0.062500 0.093750           64           64.0        5        5     2120\n",
      "0.054688 0.046875          128          128.0        2        2      262\n",
      "0.074219 0.093750          256          256.0        6        6      174\n",
      "0.056641 0.039062          512          512.0        7        7       68\n",
      "0.054688 0.052734         1024         1024.0        1        1      174\n",
      "0.059082 0.063477         2048         2048.0        2        2      484\n",
      "0.055176 0.051270         4096         4096.0        2        2      524\n",
      "0.060059 0.064941         8192         8192.0        7        7      542\n",
      "0.063538 0.067017        16384        16384.0        2        2      252\n",
      "0.062927 0.062317        32768        32768.0        1        1      240\n",
      "0.063065 0.063202        65536        65536.0        2        2      148\n",
      "0.063042 0.063019       131072       131072.0        2        2       30\n",
      "0.062759 0.062477       262144       262144.0        6        6      162\n",
      "0.063383 0.064007       524288       524288.0        5        5      644\n",
      "0.063446 0.063509      1048576      1048576.0        4        2      210\n",
      "\n",
      "finished run\n",
      "number of examples = 1463018\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.063303\n",
      "total feature number = 580609416\n"
     ]
    }
   ],
   "source": [
    "!vw -d stackoverflow_train_big.vw --loss_function hinge --oaa 10 --ngram 2 --passes 1 -b 28 --random_seed 17 --readable_model readable.vw.model -f vw.model -c\n",
    "!vw -d stackoverflow_test.vw -t -i vw.model -p stackoverflow_test_preds.txt\n",
    "y_pred = pd.read_csv('stackoverflow_test_preds.txt', names=['pred'])\n",
    "acc_final = accuracy_score(y_true_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366972928562738\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(acc_final)\n",
    "print(round((acc_final-acc_test)*100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** How large is the gain after training with 2x the data (training `stackoverflow_train.vw` + validation `stackoverflow_valid.vw`) versus the model trained solely on `stackoverflow_train.vw`?\n",
    " - 0.1%\n",
    " - ##### 0.4%\n",
    " - 0.8%\n",
    " - 1.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only just scratched the surface with Vowpal Wabbit in this assignment. Here are some hints on what to do next:\n",
    " - multilabel classification (`multilabel_oaa` argument) – data format perfectly matches with this type of problem\n",
    " - Tuning VW parameters with hyperopt. VW developers say that the accuracy strongly depends on gradient descent (`initial_t` and `power_t`) parameters. Also, we can test different loss functions i.e. train logistic regression and linear SVM\n",
    " - Learn about factorization machines and its implementation in VW (the `lrq` argument)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
